<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    
    <!-- SEO Meta Tags -->
    <meta name="description" content="2025 Workshop for AI Agent Reasoning and Decision-Making">
    <meta name="keywords" content="faacs, formal approaches, advanced computing systems, software systems,faacs 2022, faacs2022, ecsa, ecsa 2022, ecsa2022, workshop, formal methods, software architecture" />
    <meta name="author" content="Inovatik">
    <meta name="google-site-verification" content="8OG93GQ7bpeJaK3Y69Ls7-NG-rsPOafOScpkIHHjRWA" />

    <!-- OG Meta Tags to improve the way the post looks when you share the page on LinkedIn, Facebook, Google+ -->
    <meta property="og:site_name" content="AI RDM 2025" /> <!-- website name -->
    <meta property="og:site" content="https://ai-agent-reasoning.com/" /> <!-- website link -->
    <meta property="og:title" content="1st International Workshop (2025) on AI Agent Reasoning and Decision-Making"/> <!-- title shown in the actual shared post -->
    <meta property="og:description" content="1st International Workshop on Safe Reinforcement Learning Theory and its Applications" /> <!-- description shown in the actual shared post -->
    <meta property="og:image" content="" /> <!-- image link, make sure it's jpg -->
    <meta property="og:url" content="" /> <!-- where do you want your post to link to -->
    <meta property="og:type" content="article" />

    <!-- Website Title -->
    <title>  1st International Workshop (2025) on AI Agent Reasoning and Decision-Making</title>

    <!-- Styles -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700&display=swap&subset=latin-ext" rel="stylesheet">
    <link href="css/bootstrap.css" rel="stylesheet">
    <link href="css/fontawesome-all.css" rel="stylesheet">
    <link href="css/swiper.css" rel="stylesheet">
    <link href="css/magnific-popup.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet">

    <!-- Favicon  -->
    <link rel="icon" href="images/favicon.png">
    <link rel="icon" type="image/x-icon" href="images/logo-mini.ico" />
</head>
<body data-spy="scroll" data-target=".fixed-top">

    <!-- Preloader -->
    <div class="spinner-wrapper">
        <div class="spinner">
            <div class="bounce1"></div>
            <div class="bounce2"></div>
            <div class="bounce3"></div>
        </div>
    </div>
    <!-- end of preloader -->


    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark navbar-custom fixed-top">
        <div class="container">

            <!-- Text Logo - Use this if you don't have a graphic logo -->
            <!-- <a class="navbar-brand logo-text page-scroll" href="index.html">Tivo</a> -->

            <!-- Image Logo -->
            <!-- <a class="navbar-brand logo-image" href="index.html"><img src="images/logo.svg" alt="alternative"></a> -->
            <a class="navbar-brand logo-image" href="https://ai-agent-reasoning.com/" style="text-decoration: none;">AI Agent Reasoning 2025</a>

            <!-- Mobile Menu Toggle Button -->
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExampleDefault" aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-awesome fas fa-bars"></span>
                <span class="navbar-toggler-awesome fas fa-times"></span>
            </button>
            <!-- end of mobile menu toggle button -->

            <div class="collapse navbar-collapse" id="navbarsExampleDefault">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link page-scroll" href="#header">HOME <span class="sr-only">(current)</span></a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link page-scroll" href="#motivation">Motivation and scope</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link page-scroll" href="#topics">Topics of Interest</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link page-scroll" href="#submit">Registration</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link page-scroll" href="#program">Speakers</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link page-scroll" href="#organization">Organization</a>
                    </li>

                    
            </div>
        </div> <!-- end of container -->
    </nav> <!-- end of navbar -->
    <!-- end of navigation -->


    <!-- Header -->
    <header id="header" class="header">
        <div class="header-content">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-xl-12"> <!-- col-xl-6 -->
                        <div class="text-container">
                            <h1>AI Agent Reasoning and Decision-Making Workshop 2025 (AIR 2025)</h1>
                            <p class="p-large">The 1st International Workshop on AI Agent Reasoning and Decision-Making. This workshop will be held online, <strong>February 12, 2025</strong>.</p>
                            <p class="p-large"><strong>Registration Deadline: Feb 10, 2025</strong></p>
                            <a class="btn-solid-lg page-scroll" href="#submit">Free Registration</a>
                        </div> <!-- end of text-container -->
                    </div> <!-- end of col -->
                   
                </div> <!-- end of row -->
            </div> <!-- end of container -->
        </div> <!-- end of header-content -->
    </header> <!-- end of header -->
   <!--  <svg class="header-frame" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="none" viewBox="0 0 1920 310"><defs><style>.cls-1{fill:#003FBD;}</style></defs><title>header-frame</title><path class="cls-1" d="M0,283.054c22.75,12.98,53.1,15.2,70.635,14.808,92.115-2.077,238.3-79.9,354.895-79.938,59.97-.019,106.17,18.059,141.58,34,47.778,21.511,47.778,21.511,90,38.938,28.418,11.731,85.344,26.169,152.992,17.971,68.127-8.255,115.933-34.963,166.492-67.393,37.467-24.032,148.6-112.008,171.753-127.963,27.951-19.26,87.771-81.155,180.71-89.341,72.016-6.343,105.479,12.388,157.434,35.467,69.73,30.976,168.93,92.28,256.514,89.405,100.992-3.315,140.276-41.7,177-64.9V0.24H0V283.054Z"/></svg> -->
    <!-- end of header -->


   


    <!-- Motivation -->
    <div id="motivation" class="tabs">
      <div class="container">
          <div class="row">
              <div class="col-lg-12">
                  <div class="text-container">
                      <h2>Motivation and Scope</h2>
                      <div class="box"> 
                      <p>
                      As AI systems continue to evolve, their ability to reason and make decisions in complex, uncertain, and dynamic environments is paramount. This workshop aims to bring together researchers from  academia and industry to address pressing questions, including: 
                      <ul class="list-unstyled li-space-lg">
                        <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">How can AI systems emulate human-like reasoning and decision-making processes? </div>
                        </li>
                        <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">What are the latest algorithms, frameworks, and tools enabling robust decision-making under uncertainty?</div>
                        </li>
                        <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">How do we ensure ethical, transparent, and fair decision-making in AI systems?</div>
                        </li>
                      </ul> 
                      By fostering discussions on these and related topics, AIR 2025 seeks to advance the development of intelligent systems that can operate autonomously, adaptively, and responsibly.
                       </p>
                       </div>

                      <p>
                      <!-- <strong>
                       The goal of the workshop is to foster integration between formal methods and software architecture promoting new connections and synergies between the two research communities in order to address the challenges of the upcoming generation of computing systems.
                      </strong> -->
                      </p>
                  </div> <!-- end of text-container -->
              </div> <!-- end of col -->
          </div> <!-- end of row -->
      </div> <!-- end of container -->
    </div> <!-- end of tabs -->
    <!-- end of motivation -->

    <!-- topics -->
    <div id="topics" class="basic-1">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="text-container">
                        <h2>Topics of Interest</h2>
                        Areas of interest include, but are not limited to:</p>
                        <ul class="list-unstyled li-space-lg">
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Logic-based and probabilistic reasoning</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Reinforcement learning and sequential decision-making</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Causal inference in AI systems</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Decision making under uncertainty</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Multi-agent decision-making and game theory</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Human-in-the-loop decision-making processes</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Uncertainty quantification</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Ethics, fairness, and accountability in AI decision-making</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Decision-making under risk</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Tools and benchmarks for evaluating reasoning and decision-making in AI</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Explainability, transparency, and interpretability of AI Reasoning</div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">Reliability of AI Reasoning</div>
                            </li>
                        </ul>
                    </div> <!-- end of text-container -->
                </div> <!-- end of col -->
            </div> <!-- end of row -->
        </div> <!-- end of container -->
    </div> <!-- end of basic-1 -->
    <!-- end of topics -->

    <!-- Submission -->
    <div id="submit" class="tabs">
        <div class="container">
            <div class="row">
              <div class="col-lg-12">
                  <div class="text-container">
                      <h2>Registration</h2>
                      <p>We welcome the researchers and students who are interested in AI reasoning and decision-making to join us!   To receive relevant workshop information in time, please click the following link to register</strong>.</p>

                      <!-- <p>We solicit the following contribution types:</p>

                      <ul class="list-unstyled li-space-lg">
                          <li class="media">
                              <i class="fas fa-square"></i>
                              <div class="media-body"><strong>Full paper</strong> (12 pages + 2 extra pages for references): original research contributions, case studies, or report on work or experiences in industry.</div>
                          </li>
                          <li class="media">
                              <i class="fas fa-square"></i>
                              <div class="media-body"><strong>Short papers</strong> (8 pages + 2 extra pages for references): work-in-progress, new and disruptive ideas, techniques and/or tools or extensions not fully validated yet.</div>
                          </li>
                      </ul> -->

                      <p><a class="btn-solid-reg page-scroll" href="https://forms.gle/jxwx1uJbvrDVTfgJ8">Registration</a></p>
                  </div> <!-- end of text-container -->
              </div> <!-- end of col -->
             
        </div> 
    </div> 
    <!-- end of Program -->

    <!-- Program -->
    <div id="program" class="basic-1">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="text-container">
                        <h2>Speakers</h2>
                        <!-- <strong> TBD </strong> -->
                        <ul class="list-unstyled li-space-lg">

                <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/yuandong-tian.png" width="210px" style="max-width: 100%;"/><br />
                </p> 
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://yuandong-tian.com/"><b>Yuandong Tian</b>.</a> Yuandong Tian is a Research Scientist Director in Meta GenAI, leading a group for Llama reasoning. His research direction covers multiple aspects of decision making, including reinforcement learning, planning and efficiency, as well as theoretical understanding of LLMs. He is the project lead for OpenGo project, an efficient replicate of AlphaZero that beats professional players with a single GPU during inference, serves as the main mentor of StreamingLLM and GaLore that improve the training and inference of LLM, and is the first-author recipient of 2021 ICML Outstanding Paper Honorable Mentions and 2013 ICCV Marr Prize Honorable Mentions, and also received the 2022 CGO Distinguished Paper Award. Prior to that, he worked in Google Self-driving Car team in 2013-2014 and received a Ph.D in Robotics Institute, Carnegie Mellon University in 2013. He has been appointed as area chairs for NeurIPS, ICML, AAAI, CVPR and AIStats.
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>Towards a unified framework of Neural and Symbolic Decision Making</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b> Large Language Models (LLMs) have made impressive achievement while still struggling with complex tasks that require advanced decision-making done by reasoning, planning and optimization. While longer chains-of-thoughts are used in SoTA systems and work better, such system still cannot achieve the performance of traditional symbolic solvers which provide precise, guaranteed solutions to well-defined problems. Two research opportunities emerge: first, how to leverage the strengths of both by integrating neural and symbolic components into one system, and second, how to understand why the two kinds of systems have such distinct natures and whether there is a way to unite them from the first principles. In this talk, we will discuss our published works on both sides.
</div></li>
                        <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                        <!-- <p style="text-align: center;">
                            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>  -->
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                 <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/dawn-berkeley.jpg" width="210px" style="max-width: 100%;"/><br />
                </p> 
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://dawnsong.io/"><b>Dawn Song</b>.</a> Dawn Song is a Professor in the Department of Electrical Engineering and Computer Science at UC Berkeley. Her research interest lies in AI and deep learning, blockchain/web3, security and privacy. She is the recipient of various awards including the MacArthur Fellowship, the Guggenheim Fellowship, the NSF CAREER Award, the Alfred P. Sloan Research Fellowship, the MIT Technology Review TR-35 Award, and several Test-of-Time and Best Paper Awards from top conferences in Computer Security and Deep Learning. She is an ACM Fellow and an IEEE Fellow. She is ranked the most cited scholar in computer security (AMiner Award). She obtained her Ph.D. degree from UC Berkeley. Prior to joining UC Berkeley as a faculty, she was a faculty at Carnegie Mellon University from 2002 to 2007. She is also a serial entrepreneur and has been named on the Female Founder 100 List by Inc. and Wired25 List of Innovators.
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>TBD</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b> TBD.</div></li>
                        <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                        <!-- <p style="text-align: center;">
                            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>  -->
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/hanna.png" width="260px" style="max-width: 100%;"/><br />
                </p> 
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://homes.cs.washington.edu/~hannaneh/"><b>Hannaneh Hajishirzi</b>.</a> Hanna Hajishirzi is the Torode Family Associate Professor in the Allen School of Computer Science and Engineering at the University of Washington and a Senior Director of NLP at AI2.  
Her current research delves into various domains within Natural Language Processing (NLP) and Artificial Intelligence (AI), with a particular emphasis on accelerating the science of language modeling, broadening their scope, and enhancing their applicability and usefulness for human lives. She has published over 140 scientific articles in prestigious journals and conferences across ML, AI, NLP, and Computer Vision. She is the recipient of numerous awards, including the Sloan Fellowship, NSF CAREER Award, Intel Rising Star Award, Allen Distinguished Investigator Award, Academic Achievement UIUC Alumni Award, and Innovator of the Year Award by GeekWire. The work from her lab has been nominated for or has received best paper awards at various conferences and has been featured in numerous magazines and newspapers.
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>Open Training Recipes for Reasoning in Language Models</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b> In this talk, I will present my team's efforts in training language models to develop reasoning capabilities. Specifically, I will discuss how we built Tulu 3, a state-of-the-art post-trained language model that surpasses DeepSeek V3 and GPT-4o. I will outline our comprehensive, open training recipe, covering data curation, supervised fine-tuning, preference tuning, and our innovative reinforcement learning method with verifiable rewards (RLVR). </div></li>
                        <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                        <!-- <p style="text-align: center;">
                            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>  -->
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/bo-an.jpg" width="210px" style="max-width: 100%;"/><br />
                </p> 
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://personal.ntu.edu.sg/boan/"><b>Bo An</b>.</a> Bo An is a President's Chair Professor and Head of Division of Artificial Intelligence at the College of Computing and Data Science of the Nanyang Technological University (NTU). He is also Director for Centre of AI-for-X of NTU. He was a Nanyang Assistant Professor during 2014-2018. Prior to join NTU in 2013, he spent one year as an Associate Professor at the Institute of Computing Technology of the Chinese Academy of Sciences. During October 2010 to June 2012, he was a Postdoctoral Researcher at the University of Southern California, working with Professor Milind Tambe. He received the Ph.D degree in Computer Science from the University of Massachusetts, Amherst, where he was advised by Professor Victor Lesser. His research interests include artificial intelligence, multi-agent systems, computational game theory, reinforcement learning, automated negotiation, and optimization. He has published over 150 referred papers at top conferences (AAMAS, IJCAI, AAAI, ICML, NeurIPS, ICLR, KDD, ICAPS, EC, UAI, AISTATS, and WWW) and journals (JAAMAS, AIJ and ACM/IEEE Transactions). His work on applying game theory to security has been applied to develop game-theoretic randomization software that is currently deployed by the United States Federal Air Marshals Service, the United States Coast Guard, and wildlife conservation organizations. He has served as program committee members for many top conferences and was co-chair for some key international conferences/symposia. He was named to IEEE Intelligent Systems' "AI's 10 to Watch" list for 2018. He is a member of the editorial board of Journal of Artificial Intelligence Research (JAIR) and the Associate Editor of Artificial Intelligence Journal (AIJ), Journal of Autonomous Agents and Multi-agent Systems (JAAMAS), IEEE Intelligent Systems, ACM Transactions on Intelligent Systems and Technology, and ACM Transactions on Autonomous and Adaptive Systems. He was elected to the board of directors of IFAAMAS, senior member of AAAI, and ACM Distinguished Member. He was PC Co-Chair of AAMAS'20 and General Co-Chair of AAMAS'23. He will be PC Chair of IJCAI'27.
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>From RL-based to LLM-powered Agents</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b> In the early days of tackling AI problems involving complex cooperation and strategic interactions, reinforcement learning has proven effective in learning efficient policies for large-scale optimization problems that are beyond the scalability of traditional algorithmic approaches. Recently, the use of large language models (LLMs) as computational engines has given rise to a new paradigm: LLM-powered agents capable of addressing complex problems across various domains. This talk will explore our recent work within these paradigms and offer insights into the development of scalable, efficient, and distributed artificial general intelligence.</div></li>
                        <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                        <!-- <p style="text-align: center;">
                            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>  -->
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/graham.jpeg" width="210px" style="max-width: 100%;"/><br />
                </p> 
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://www.phontron.com/"><b>Graham Neubig</b>.</a> Graham Neubig is an Associate Professor at the Carnegie Mellon University Language Technology Institute in the School of Computer Science, and work with a bunch of great students in the lab NeuLab. His is also a chief scientist at All Hands AI, where AI agents are built for software development. His research focuses on machine learning and natural language processing. In particular, his is interested in basic research and applications of large language models, with a particular focus on question answering, code generation, multilingual processing, and evaluation/interpretability.
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>LLM Agents that Learn from Experience</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b> In this talk I will discuss how LLM agents can learn from their past experiences, specifically in the context of web agents. Specifically, I will discuss two different varieties of methods to do so. First, I will discuss agent workflow memory, an online learning method that takes the agent's past experiences and references them in future tasks. Second, I will discuss methods of using and inducing APIs in agent-based learning, demonstrating that agents with APIs can outperform those who perform web tasks directly, and discuss methods of inducing reusable APIs from past experiences.</div></li>
                        <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                        <!-- <p style="text-align: center;">
                            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>  -->
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/chi_jin.jpeg" width="210px" style="max-width: 100%;"/><br />
                </p> 
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://sites.google.com/view/cjin/"><b>Chi Jin</b>.</a>Chi Jin is an assistant professor at the Electrical and Computer Engineering department of Princeton University. He obtained his PhD degree in Computer Science at University of California, Berkeley, advised by Michael I. Jordan. His research primarily focuses on theoretical machine learning, particularly nonconvex optimization and reinforcement learning (RL), with recent interests extending to LLM reasoning and agents. In nonconvex optimization, he provided the first proof showing that first-order algorithm (stochastic gradient descent) is capable of escaping saddle points efficiently. In RL, he provided the first efficient learning guarantees for Q-learning and least-squares value iteration algorithms when exploration is necessary. His works also lay the theoretical foundation for RL with function approximation, multi-agency and partial observability. He is the recipient of NSF CAREER award and Sloan fellowship. 
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b> We introduce Goedel-Prover, an open-source Large Language Model (LLM) that achieves the state-of-the-art performance in automated formal proof generation for mathematical problems. A key challenge in training LLMs for formal reasoning is the scarcity of formal data. To address this, we train formalizers to translate a substantial corpus of mathematical problems from natural language into formal language (Lean 4) in various styles, producing 1.64 million syntactically correct and content-accurate formal statements. We then train a prover iteratively, alternating between generating verified proofs from statements and refining the model using these proofs. Our model outperforms all existing open-source models for whole-proof generation across multiple benchmarks. On the miniF2F benchmark (Pass@32), our model attains a 57.6% success rate, surpassing the previous best open-source model by 7.6%. On PutnamBench, it successfully solves 7 problems (Pass@512), ranking first on the leaderboard. Furthermore, it generates 29.7K formal proofs for Lean Workbook problems, nearly doubling the 15.7K produced by earlier works.</div></li>
                        <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                        <!-- <p style="text-align: center;">
                            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>  -->
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/junyang-lin.jpeg" width="210px" style="max-width: 100%;"/><br />
                </p>    
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://justinlin610.github.io/"><b>Junyang Lin</b>.</a> Junyang Lin, a senior staff engineer at Alibaba, currently serves as the tech lead for <a href="https://github.com/QwenLM"><b>Qwen</b></a>. His research areas include natural language processing and multi-modal representation learning, with a particular focus on large-scale foundation models. He has published papers in top-tier conferences such as NeurIPS, ICML, and ACL, and his Google Scholar citation count exceeds 9,700. Since 2023, he has primarily been responsible for the development, open-sourcing, and application of the Qwen series of large models. The models he has developed include the large language model Qwen2.5, the vision-language large model Qwen2-VL, the speech-language large model Qwen2-Audio, the code large model Qwen2.5-Coder, and the math large model Qwen2.5-Math. He is dedicated to promoting the open-source availability of large models. Currently, the Qwen series of models has been downloaded over 100 million times globally, with 87,000 derivative models created based on Qwen and more than 8 million developers worldwide.
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>Qwen: Towards Generalist Models</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b> Since Alibaba launched the Qwen series of large models in 2023, the Qwen series of large language models and multimodal large models have been continuously updated and improved. This presentation will introduce the latest developments in the Qwen series of models, including the current performance and technical implementation behind the large language models Qwen2.5, the mathematical large models Qwen2.5-Math, the coding large models Qwen2.5-Coder, the vision-language large models Qwen2-VL, and the speech-language large models Qwen2-Audio, etc. Additionally, this presentation will also cover the future development directions of the Qwen series.</div></li>
                       
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                <div class="text-container" >
                <p style="text-align: center;">
                    <img src="images/speakers-pics/huansun.png" width="210px" style="max-width: 100%;"/><br />
                </p>    
                    <div class="box">    
                    <li class="media"><i class="fas fa-square"></i>
                        <div class="media-body"><a href="https://u.osu.edu/ihudas/people/"><b>Huan Sun</b>.</a> Huan Sun is an endowed College of Engineering Innovation Scholar and associate professor in the Department of Computer Science and Engineering at The Ohio State University. Her research interests lie in natural language processing and artificial intelligence, especially building and benchmarking LLMs and agents and mitigating their safety risks. Huan received Best Paper Finalist at CVPR’24, Honorable Mentions for Best Paper Awards at ACL’23 (two papers), 2022 ACM SIGMOD Research Highlight Award, Best Paper Award at BIBM’21, Google Research Scholar and Google Faculty Award, NSF CAREER Award, OSU Lumley Research Award, and SIGKDD Ph.D. Dissertation Runner-Up Award, among others. Her team won third place in the first Alexa Prize TaskBot challenge in 2022. Huan received her Ph.D. from the University of California, Santa Barbara and B.S. from the University of Science and Technology of China.
                        </div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>Understanding Reasoning in LLMs and Agents: From Grokking of Implicit Reasoning to Test-Time Scaling with Verifiers</strong>.</div></li>
                        <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b>The past two years have seen language agents emerge as powerful AI systems, driven by advances in large language and multimodal models. This talk presents our recent work on web agents and agents for science, showcasing the potential of cutting-edge models like OpenAI o1 and DeepSeek R1. A critical factor enabling these agents lies in the “reasoning” capabilities of LLMs -- yet fundamental questions about LLM/agent reasoning remain unanswered: (1) As the backbone model architecture, how promising or limited is Transformer for implicit multi-step reasoning? (2) During test-time scaling, under what conditions do tree search and iterative correction methods outperform simpler approaches? In the second part of this talk, I will discuss some findings from our recent work that can partly answer these questions: (1) After a "grokking" phase, transformers exhibit varying degrees of generalization across different reasoning tasks, as demonstrated through rigorous controlled experiments; (2) For test-time scaling, tree search and iterative correction require highly accurate verifiers (~90% accuracy) to outperform simpler re-ranking methods. </div></li>
                        <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                        <!-- <p style="text-align: center;">
                            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </p>  -->
                        <p> </p>        
                        <br>
                        <br>                                   
                    </div>
                </div>


                <div class="text-container" >
                    <p style="text-align: center;">
                        <img src="images/speakers-pics/yuxiang_wu.jpeg" width="190px" style="max-width: 100%;"/><br />
                    </p>    
                        <div class="box">    
                        <li class="media"><i class="fas fa-square"></i>
                            <div class="media-body"><a href="https://scholar.google.com/citations?user=ZN1uIRQAAAAJ&hl=en&oi=ao"><b>Yuxiang Wu</b>.</a> Yuxiang Wu is the co-founder and CTO of Weco AI, where he leads efforts to build AI agents that automate scientific discovery. His research focuses on AI agents, open-domain question answering, data generation, and knowledge-augmented pre-trained language models, and his work has been cited over 4,000 times. He has received multiple honors, including the Best Paper Award at AKBC 2020, first place in the NeurIPS 2020 EfficientQA Competition, and the Best Poster Award at the ENLSP Workshop during NeurIPS 2022.
                            </div></li>
                            <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>AIDE: Searching Intelligence in the Space of Solutions</strong>.</div></li>
                            <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b>AI-Driven Exploration (AIDE) is a reasoning-centric agent powered by large language models (LLMs) that tackles the iterative and often uncertain process of machine learning engineering as a structured decision-making problem. By framing model development as code optimization and representing trial-and-error as a tree search over potential solutions, AIDE systematically explores and refines promising avenues. This approach enables it to autonomously handle the complexity and uncertainty inherent in real-world ML design, adaptively allocating computational resources to generate stronger outcomes. Moreover, AIDE’s tree-search formulation fosters interpretability and transparency of decision steps, aligning with the workshop’s emphasis on ethical and robust reasoning. Our results demonstrate state-of-the-art performance on multiple benchmarks—including Kaggle evaluations, OpenAI’s MLE-Bench, and METR’s RE-Bench—illustrating how an agent-driven paradigm can elevate the efficiency, reliability, and accountability of AI-powered decision-making. </div></li>
                            <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                            <!-- <p style="text-align: center;">
                                <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                            </p>  -->
                            <p> </p>        
                            <br>
                            <br>                                   
                        </div>
                    </div>


                    <div class="text-container" >
                        <p style="text-align: center;">
                            <img src="images/speakers-pics/xidong_feng.jpg" width="210px" style="max-width: 100%;"/><br />
                        </p>    
                            <div class="box">    
                            <li class="media"><i class="fas fa-square"></i>
                                <div class="media-body"><a href="https://waterhorse1.github.io/"><b>Xidong Feng</b>.</a> TBD
                                </div></li>
                                <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>TBD</strong>.</div></li>
                                <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b>TBD </div></li>
                                <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                                <!-- <p style="text-align: center;">
                                    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                                </p>  -->
                                <p> </p>        
                                <br>
                                <br>                                   
                            </div>
                        </div>

                    
                    <div class="text-container" >
                            <p style="text-align: center;">
                                <img src="images/speakers-pics/yan_song.png" width="210px" style="max-width: 100%;"/><br />
                            </p>    
                                <div class="box">    
                                <li class="media"><i class="fas fa-square"></i>
                                    <div class="media-body"><a href="https://yansong97.github.io/"><b>Yan Song</b>.</a> TBD
                                    </div></li>
                                    <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>TBD</strong>.</div></li>
                                    <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b>TBD </div></li>
                                    <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                                    <!-- <p style="text-align: center;">
                                        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                                    </p>  -->
                                    <p> </p>        
                                    <br>
                                    <br>                                   
                                </div>
                    </div>

                    <div class="text-container" >
                        <p style="text-align: center;">
                            <img src="images/speakers-pics/kun_shao.jpeg" width="210px" style="max-width: 100%;"/><br />
                        </p>    
                            <div class="box">    
                            <li class="media"><i class="fas fa-square"></i>
                                <div class="media-body"><a href="https://scholar.google.com/citations?user=4CNMLWAAAAAJ&hl"><b>Kun Shao</b>.</a> Kun Shao is a Principal Research Scientist and Project Manager at Huawei London Research Center. Before joining Huawei, Kun Shao received a Ph.D. degree from the Institute of Automation, Chinese Academy of Sciences. He has received several awards and has published several papers in top conferences. His main research interests are AI agents, reinforcement learning, and multi-agent systems. He has also contributed to the application of machine learning to mobile phones, robotics, autonomous driving, and game AI.
                                </div></li>
                                <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Title: </b> <strong>Towards generalist GUI agents: model and optimization</strong>.</div></li>
                                <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Abstract: </b>GUI agents are responsible for operating devices to fulfill user requests, enabling antonomous interactions. To achieve Generalist GUI Agents, we propose a new generation of methods to achieve 1) Comprehensive Benchmarking; 2) Lightweight Model; and 3) Efficient Optimization. In this talk, we will present SPA-BENCH, a comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based agents in an interactive environment that simulates real-world conditions. Then, to address the computational constraints inherent to smartphones, we introduce a lightweight Action Transformer (AcT) integrated with a fine-tuned VLM for real-time decision-making. Finally, we will introduces DistRL and VSC-RL, the novel frameworks designed to enhance the efficiency of online RL fine-tuning for GUI agents. </div></li>
                                <!-- <li class="media">&nbsp;&nbsp;<div class="media-body"><b>Talk Video: </b> </div></li> -->
                                <!-- <p style="text-align: center;">
                                    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uvXb0P1knRw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                                </p>  -->
                                <p> </p>        
                                <br>
                                <br>                                   
                            </div>
                </div>

                
                </div> <!-- end of text-container -->
                    <div class="text-container">
                     
                    </div>
                </div> <!-- end of col -->
            </div> <!-- end of row -->
        </div> <!-- end of container -->
    </div> <!-- end of basic-1 -->
    <!-- end of Program -->


    <!-- Organization -->
 <!--    <div id="organization" class="tabs">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="text-container">
                        <ul class="list-unstyled li-space-lg">                           
                          <h2>Workshop Organizers</h2>
                            <ul class="list-unstyled li-space-lg">
                                <li class="media">
                                    <p style="text-align: center;">
                                        <img src="images/speakers-pics/junyang-lin.jpeg" width="210px" style="max-width: 100%;"/><br />
                                    </p>    
                                    <i class="fas fa-square"></i>
                                    <div class="media-body"><a href="http://www0.cs.ucl.ac.uk/staff/Jun.Wang/"><b>Jun Wang</b> (Professor, University College London)</a> </div>
                                </li>
                                <li class="media">
                                    <i class="fas fa-square"></i>
                                    <div class="media-body"><a href="https://personal.ntu.edu.sg/boan/"><b>Bo An</b> (Professor, Nanyang Technological University)</a> </div>
                                </li>
                                <li class="media">
                                    <i class="fas fa-square"></i>
                                    <div class="media-body"><a href="https://yuandong-tian.com/"><b>Yuandong Tian</b> (Research Scientist Director, Meta AI (FAIR))</a> </div>
                                </li>
                                <li class="media">
                                    <i class="fas fa-square"></i>
                                    <div class="media-body"><a href="https://mengfn.github.io/"><b>Meng Fang</b> (Assistant Professor, University of Liverpool)</a> </div>
                                </li>
                                <li class="media">
                                    <i class="fas fa-square"></i>
                                    <div class="media-body"><a href="https://sca.shanghaitech.edu.cn/sca_en/2020/0903/c7933a173623/page.htm"><b>Zheng Tian</b> (Assistant Professor, Shanghai Tech)</a> </div>
                                </li>                                
                                <li class="media">
                                    <i class="fas fa-square"></i>
                                    <div class="media-body"><a href="https://people.eecs.berkeley.edu/~shangding.gu/index.html"><b>Shangding Gu</b> (Postdoc, UC Berkeley)</a> </div>
                                </li>
                               </ul>                         
                    </div> 
                </div> 
            </div> 
        </div> 
    </div>  -->
  

 

 <!-- Organization -->
<div id="organization" class="tabs">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="text-container">
                    <h2>Workshop Organizers</h2>
                    <br>
                    <div class="organizers-container">
                        <div class="organizer">
                            <img src="images/organizers-pics/jun-wang.jpg" alt="Jun Wang">
                            <div class="organizer-info">
                                <a href="http://www0.cs.ucl.ac.uk/staff/Jun.Wang/"><b>Jun Wang</b></a><br>
                                Professor, University College London
                            </div>
                        </div>
                        <div class="organizer">
                            <img src="images/speakers-pics/bo-an.jpg" alt="Bo An">
                            <div class="organizer-info">
                                <a href="https://personal.ntu.edu.sg/boan/"><b>Bo An</b></a><br>
                                Professor, Nanyang Technological University
                            </div>
                        </div>
                        <div class="organizer">
                            <img src="images/speakers-pics/yuandong-tian.png" alt="Yuandong Tian">
                            <div class="organizer-info">
                                <a href="https://yuandong-tian.com/"><b>Yuandong Tian</b></a><br>
                                Research Scientist Director, Meta GenAI.
                            </div>
                        </div>
                        <div class="organizer">
                            <img src="images/organizers-pics/meng-fang.jpeg" alt="Meng Fang">
                            <div class="organizer-info">
                                <a href="https://mengfn.github.io/"><b>Meng Fang</b></a><br>
                                Assistant Professor, University of Liverpool
                            </div>
                        </div>
                        <div class="organizer">
                            <img src="images/organizers-pics/zheng-tian.png" alt="Zheng Tian">
                            <div class="organizer-info">
                                <a href="https://sca.shanghaitech.edu.cn/sca_en/2020/0903/c7933a173623/page.htm"><b>Zheng Tian</b></a><br>
                                Assistant Professor, Shanghai Tech
                            </div>
                        </div>
                        <div class="organizer">
                            <img src="images/organizers-pics/shangding-gu.png" alt="Shangding Gu">
                            <div class="organizer-info">
                                <a href="https://people.eecs.berkeley.edu/~shangding.gu/index.html"><b>Shangding Gu</b></a><br>
                                Postdoc, UC Berkeley
                            </div>
                        </div>
                    </div>
                </div> <!-- end of text-container -->
            </div> <!-- end of col -->
        </div> <!-- end of row -->
    </div> <!-- end of container -->
</div> <!-- end of organization -->

<style>
.organizers-container {
    display: flex;
    flex-wrap: wrap;
    justify-content: center;
    gap: 95px; /* 减少间距，使更多图片显示 */
    text-align: center;
}

.organizer {
    width: 140px; /* 适当减小宽度 */
    text-align: center;
}

.organizer img {
    width: 100%;
    height: 205px; /* 统一图片大小 */
    object-fit: cover; /* 让图片填充框架 */
    border-radius: 45%;
    display: block;
    margin: 0 auto 8px;
}

.organizer-info {
    font-size: 13px; /* 调整字体大小 */
    line-height: 1.3;
}
</style>








    <!-- Social -->
    <div class="form">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="icon-container">
                        <!-- <span class="fa-stack">
                            <a href="https://twitter.com/faacs_ws">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-twitter fa-stack-1x"></i>
                            </a>
                        </span> -->
                        <span class="fa-stack">
                            <a href="https://github.com/openreasoner/openr">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fas fa-globe fa-stack-1x"></i>
                            </a>
                        </span>
                        <span class="fa-stack">
                            <a href="mailto:shangding.gu@berkeley.edu">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="far fa-envelope fa-stack-1x"></i>
                            </a>
                        </span>
                    </div> <!-- end of col -->
                </div> <!-- end of col -->
            </div> <!-- end of row -->
        </div> <!-- end of container -->
    </div> <!-- end of form -->

    <div class="footer">
        <div class="container">
            <div class="row justify-content-md-center">
                <div class="col-md-auto">
                    <div class="footer-col middle">
                        <h4>Relevant Links</h4>
                        <ul class="list-unstyled li-space-lg p-small">
                            <li class="media">
                                <i class="fas fa-square"></i>
                                <div class="media-body">AI-RDM 2025 <a class="white" href="https://www.mfi2022.com/">https://github.com/openreasoner/openr</a></div>
                            </li>
                        </ul>
                    </div>
                </div> <!-- end of col -->
                <div class="col-md-auto">
                    <div class="footer-col last">
                        <h4>Venue</h4>
                        <ul class="list-unstyled li-space-lg p-small">
                            <li class="media">
                                <i class="fas fa-map-marker-alt"></i>
                                <div class="media-body">Online Workshop</div>
                            </li>

                        </ul>
                    </div>
                </div> <!-- end of col -->
            </div> <!-- end of row -->
        </div> <!-- end of container -->
    </div> <!-- end of footer -->
    <!-- end of footer -->


    <!-- Copyright -->
    <div class="copyright">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <p class="p-small">Copyright © 2025 <a href="https://inovatik.com">Template by Inovatik</a></p>
                </div> <!-- end of col -->
            </div> <!-- enf of row -->
        </div> <!-- end of container -->
    </div> <!-- end of copyright -->
    <!-- end of copyright -->


    <!-- Scripts -->
    <script src="js/jquery.min.js"></script> <!-- jQuery for Bootstrap's JavaScript plugins -->
    <script src="js/popper.min.js"></script> <!-- Popper tooltip library for Bootstrap -->
    <script src="js/bootstrap.min.js"></script> <!-- Bootstrap framework -->
    <script src="js/jquery.easing.min.js"></script> <!-- jQuery Easing for smooth scrolling between anchors -->
    <script src="js/swiper.min.js"></script> <!-- Swiper for image and text sliders -->
    <script src="js/jquery.magnific-popup.js"></script> <!-- Magnific Popup for lightboxes -->
    <script src="js/validator.min.js"></script> <!-- Validator.js - Bootstrap plugin that validates forms -->
    <script src="js/scripts.js"></script> <!-- Custom scripts -->
</body>
</html>
